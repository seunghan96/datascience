# 모델별 parameter 확인
library(caret)
modelLookup("C5.0")
# simple tuned model
set.seed(300)
credit <- read.csv("C:\\Users\\samsung\\Desktop\\Bitamin\\Machine Learning with R\\5장\\credit.csv")
m <- train(default ~., data=credit, method="C5.0") # train 통해, tuning parameter 이용해 model 만듬
str(m)
p <- predict(m,credit)
p <- predict(m,data=credit)
table(p,credit$default)
# customizing tuning process
# ( default값을 바꿀 수 있음 -> 특정 상황에 더 적합하게끔 )
ctrl <- trainControl(method="cv", number=10, selectionFunction="oneSE") # 10-cross validation
grid <- expand.grid(.model="tree", .trials=c(1,5,10,15,20,25,30,35), .winnow="FALSE") # C5.0의 parameter 지정
set.seed(300)
m <- train(default~., data=credit, method="C5.0",
metric='Kappa',
trControl=ctrl,
tuneGrid=grid)
m
# 앙상블 모형 (meta-learning)
# 배깅
library(ipred)
set.seed(300)
mybag <- bagging(default~., data=credit, nbagg=25)
credit_pred <- predict(mybag, data=credit)
table(credit_pred, credit$default)
library(caret) #10 cv-fold 적용해보기
set.seed(300)
modelLookup("bagging")
modelLookup("ipred")
ctrl <- trainControl(method="cv",number=10)
train(default~., data=credit, method='treebag', trControl=ctrl)
m <- train(default~., data=credit, method='treebag', trControl=ctrl)
m
str(svmBag)
svmBag$fit
bagctrl <- bagControl(fit=svmBag$fit,
predict=svmBag$pred,
aggregate=svmBag$aggregate)
set.seed(300)
svmbag <- train(default~., data=credit,"bag",
trControl=ctrl, bagControl=bagctrl)
svmbag
# 부스팅
set.seed(300)
m_adaboost <- boosting(default~., data=credit)
library(boosting)
m_adaboost <- boosting(default~., data=credit)
# 부스팅
library(M1)
# 부스팅
install.packages("M1")
library(M1)
