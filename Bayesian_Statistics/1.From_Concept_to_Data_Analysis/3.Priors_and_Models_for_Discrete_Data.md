# 3. Prior and Models for Discrete Data

## (1) Priors
We have seen that we can use prior belief when calculating the posterior probability in Bayesian Inference. So, how do we choose a prior?
A useful concept in terms of choosing priors is that of calibration.

Let's take an example. (ref : https://www.coursera.org/learn/bayesian-statistics )</br>
Suppose you are tasked with eliciting a prior distribution for θ, the proportion of taxpayers who file their returns after the deadline. After speaking with several tax experts, but before collecting data, you are reasonably confident that \thetaθ is greater than 0.05, but less than 0.20.
</br>
<img src="https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/Crg8OhhdEea3RQoRNEpMkw_3b9af2a12375baf616035c778dd5f719_l6.1_ivq1_a.svg?expiry=1582934400000&hmac=mOcllYOWUlribu1TS-ssxW8UzFjjOi7aFqdKIy66fIo" width="450" /> </br>
The prior distribution above most accurately reflects theses prior beliefs about θ. This prior assigns approximately 95% of the prior probability to the interval (0.05, 0.20). It is a strongly informative prior, but it is consistent with our prior beliefs.
</br>

### a) prior predictive distribution
prior predictive distribution is a distribution of data, which we think wi will obtain before actually see the data. For example, if we believe the "coin is a fair coin" and toss the coin 100 times, then the prior distribution of coming up heads(tails) would look like this.
</br>
</br>
<img src="https://qph.fs.quoracdn.net/main-qimg-c7fcbfcbf859ecb148cdfe8dcf436be3" width="450" /> </br>
https://qph.fs.quoracdn.net/main-qimg-c7fcbfcbf859ecb148cdfe8dcf436be3
</br>
</br>
And this would be the equation how it would look like.
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=P(y)&space;=&space;\int&space;P(y,\theta)d\theta&space;=&space;\int&space;P(y|\theta)\times&space;P(\theta)d\theta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(y)&space;=&space;\int&space;P(y,\theta)d\theta&space;=&space;\int&space;P(y|\theta)\times&space;P(\theta)d\theta" title="P(y) = \int P(y,\theta)d\theta = \int P(y|\theta)\times P(\theta)d\theta" /></a>
</br>

### b) posterior predictive distribution
posterior predictive distribution is a distribution of data we would expect to obtain if we repeat the experiment after we have seen some data from the current experiment. For example, we have tossed a coin several times as an experiment, and only 3 times out of 10 times had the coin came up with head. Then, we are more likely to have a distribution with a bit right-skewed.
</br>
<img src="https://i.stack.imgur.com/YCbPX.png" width="400" /> </br>
https://i.stack.imgur.com/YCbPX.png
</br>
</br>
And this would be the equation how it would look like.
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=P(y'|y)&space;=&space;\int&space;P(y',\theta|y)d\theta&space;=&space;\int&space;P(y'|\theta,y)\timesP(\theta\y)d\theta" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(y'|y)&space;=&space;\int&space;P(y',\theta|y)d\theta&space;=&space;\int&space;P(y'|\theta,y)\timesP(\theta\y)d\theta" title="P(y'|y) = \int P(y',\theta|y)d\theta = \int P(y'|\theta,y)\timesP(\theta\y)d\theta" /></a>
</br>
</br>

## (2) Bernoulli / Binomial data
### a) Bernoulli / binomial likelihood with uniform prior
We get a beta posterior when we use uniform prior for Bernoulli likelihood.
</br>
The Bernoulli likelihood is 
<a href="https://www.codecogs.com/eqnedit.php?latex=f(y|\theta)&space;=&space;\theta^{\sum&space;y_i}&space;(1-\theta)^{n-\sum&space;y_i}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(y|\theta)&space;=&space;\theta^{\sum&space;y_i}&space;(1-\theta)^{n-\sum&space;y_i}" title="f(y|\theta) = \theta^{\sum y_i} (1-\theta)^{n-\sum y_i}" /></a>,
</br>
and if it has an uniform prior, we can say that
<a href="https://www.codecogs.com/eqnedit.php?latex=f(\theta)&space;=&space;I_{{0\leq&space;\theta\leq&space;1}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(\theta)&space;=&space;I_{{0\leq&space;\theta\leq&space;1}}" title="f(\theta) = I_{{0\leq \theta\leq 1}}" /></a>
</br>
</br>
With these two, we can calculate the posterior probability. And this is how it will look like.
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;f(\theta|y)&=\frac{f(y|\theta)f(\theta)}{\int&space;f(y|\theta)f(\theta)d\theta}\\&space;&=\frac&space;{\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{0\leq&space;\theta\leq&space;1}}{\int_{0}^{1}\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{0\leq&space;\theta\leq&space;1}d\theta}\\&space;&=\frac{\tau&space;(n&plus;2)}{\tau&space;(\sum&space;y_i&space;&plus;1)\tau&space;(n-&space;\sum&space;y_i&space;&plus;1)}\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{{{0\leq&space;\theta\leq&space;1}}}&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;f(\theta|y)&=\frac{f(y|\theta)f(\theta)}{\int&space;f(y|\theta)f(\theta)d\theta}\\&space;&=\frac&space;{\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{0\leq&space;\theta\leq&space;1}}{\int_{0}^{1}\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{0\leq&space;\theta\leq&space;1}d\theta}\\&space;&=\frac{\tau&space;(n&plus;2)}{\tau&space;(\sum&space;y_i&space;&plus;1)\tau&space;(n-&space;\sum&space;y_i&space;&plus;1)}\theta^{\sum&space;y_i}(1-\theta)^{n-\sum&space;y_i}I_{{{0\leq&space;\theta\leq&space;1}}}&space;\end{align*}" title="\begin{align*} f(\theta|y)&=\frac{f(y|\theta)f(\theta)}{\int f(y|\theta)f(\theta)d\theta}\\ &=\frac {\theta^{\sum y_i}(1-\theta)^{n-\sum y_i}I_{0\leq \theta\leq 1}}{\int_{0}^{1}\theta^{\sum y_i}(1-\theta)^{n-\sum y_i}I_{0\leq \theta\leq 1}d\theta}\\ &=\frac{\tau (n+2)}{\tau (\sum y_i +1)\tau (n- \sum y_i +1)}\theta^{\sum y_i}(1-\theta)^{n-\sum y_i}I_{{{0\leq \theta\leq 1}}} \end{align*}" /></a>
</br>
</br>
So we can say that this posterior proability follows the following beta distribution!
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\theta|y&space;~&space;Beta(\sum&space;y_i&plus;1,&space;n-\sum&space;y_i&space;&plus;1)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta|y&space;~&space;Beta(\sum&space;y_i&plus;1,&space;n-\sum&space;y_i&space;&plus;1)" title="\theta|y ~ Beta(\sum y_i+1, n-\sum y_i +1)" /></a>
</br>
</br>

### b) Conjugate Priors
A family of distributions is referred to as conjugate if when you use a member of that family as a prior, you get another member of that family as your posterior.
</br>
For example, any beta distribution is conjuaget for the Bernoulli distribution, which means that any beta prior will give a beta
posterior. The case with the distribution with uniform prior, that we just saw in the above, is just one case of the below. ( uniform distribution is just one case of beta (1,1) )
<img src="https://miro.medium.com/max/3190/1*xjRaB2R2A3aDS8RstiErMQ.png" width="650" /> </br>
https://miro.medium.com/max/3190/1*xjRaB2R2A3aDS8RstiErMQ.png

Why do we use conjuagte priors?
It's because they make the calculation much more simpler. When we are working out with posteriors, and face an intractable integral in the denominator ( hard to recognize the form ), we get difficulty sovling this. That is why we use conjugat families, which allows us to get closed form solutions!
</br>

### c) Posterior mean and effective sample size
