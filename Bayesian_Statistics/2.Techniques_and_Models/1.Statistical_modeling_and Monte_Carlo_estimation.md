# 1. Statistical modeling and Monte Carlo estimation

## (1) Statistical Modeling
Statistical models : to imitates & approximates "data generating process"
</br>
<img src="https://i.ytimg.com/vi/yQhTtdq_y9M/maxresdefault.jpg" width="550" /> </br>
https://i.ytimg.com/vi/yQhTtdq_y9M/maxresdefault.jpg
</br>

### a. Four objectives of statistical models
1) **Quantify Uncertainty**
- ex Q) the probability of xxxx is 57%. How sure are you about the number '57'?
- ex A) confidence interval (51,63) with 99% confidence

2) **Inference**
- ex) We only know 10% of people who supported the candidate. What if we extend to the total population?

3) Measure support for hypothesis
- Polling example - hypothesis that the candidate is more popular with men than with women. 50% of women and 52% of men favored the candidate. Is thig strong
enought to support the hypothesis?

4) Prediction
- Model which does not produce realistic predictions will be useless! Very important
- Have same objective as Machine Learning.
</br>
If Machine Learning focuses on the 4) Prediction, Statistical models strive to balance these four objectives!
</br>
</br>

### b. Modeling Process
- 1 ) Understand the problem
- 2 ) Plan & Collect data
- 3 ) Explore data ( + visualization )
- 4 ) Postulate model
- 5 ) Fit model
- 6 ) Check Model
- 7 ) Iterate 4)~6)
- 8 ) Use model
</br>
</br>

## (2) Bayesian Modeling
### a. Components of Bayesian models (review)
1) likelihood : <a href="https://www.codecogs.com/eqnedit.php?latex=P(y|\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(y|\theta)" title="P(y|\theta)" /></a></br>
2) prior : <a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta)" title="P(\theta)" /></a></br>
3) posterior : <a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta|y)&space;=&space;\frac{P(\theta,y)}{P(y)}=&space;\frac{P(\theta,y)}{\int&space;P(\theta,y)d\theta}=&space;\frac{P(y|\theta)P(\theta)}{\int&space;P(y|\theta)P(\theta)d\theta}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta|y)&space;=&space;\frac{P(\theta,y)}{P(y)}=&space;\frac{P(\theta,y)}{\int&space;P(\theta,y)d\theta}=&space;\frac{P(y|\theta)P(\theta)}{\int&space;P(y|\theta)P(\theta)d\theta}" title="P(\theta|y) = \frac{P(\theta,y)}{P(y)}= \frac{P(\theta,y)}{\int P(\theta,y)d\theta}= \frac{P(y|\theta)P(\theta)}{\int P(y|\theta)P(\theta)d\theta}" /></a>
</br>
And before fitting a model, we need to specify these components.

### b. Posterior derivation
There can be a model with multiple levels (hierarchical). 
That is, a prior follows a certain distribution, and the parameter of that distribution follows another distribution, ... and so on.
</br>
Let's take a look at this expression.

<a href="https://www.codecogs.com/eqnedit.php?latex=X_i|\mu,\sigma^2&space;\sim&space;N(\mu,&space;\sigma^2)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?X_i|\mu,\sigma^2&space;\sim&space;N(\mu,&space;\sigma^2)" title="X_i|\mu,\sigma^2 \sim N(\mu, \sigma^2)" /></a>
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\mu|\sigma^2&space;\sim&space;N(m,&space;\frac{\sigma^2}{w})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\mu|\sigma^2&space;\sim&space;N(m,&space;\frac{\sigma^2}{w})" title="\mu|\sigma^2 \sim N(m, \frac{\sigma^2}{w})" /></a>
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\sigma^2&space;\sim&space;\tau^{-1}(\alpha,\beta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\sigma^2&space;\sim&space;\tau^{-1}(\alpha,\beta)" title="\sigma^2 \sim \tau^{-1}(\alpha,\beta)" /></a>
</br>
</br>
We can derive a posterior like below!
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{align*}&space;P(X_1,...X_n,\mu,\sigma^2)&=P(X_1,..X_n|\mu,\sigma^2)P(\mu|\sigma^2)P(\sigma^2)\\&space;&=\prod_{i=1}^{n}[N(X_i|\mu,\sigma^2)]\times&space;N(\mu|m,\frac{\sigma^2}{w})\times\tau^{-1}(\sigma^2|\alpha,\beta)\\&space;&=P(\mu,\sigma^2|X_1...X_n)&space;\end{align*}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;P(X_1,...X_n,\mu,\sigma^2)&=P(X_1,..X_n|\mu,\sigma^2)P(\mu|\sigma^2)P(\sigma^2)\\&space;&=\prod_{i=1}^{n}[N(X_i|\mu,\sigma^2)]\times&space;N(\mu|m,\frac{\sigma^2}{w})\times\tau^{-1}(\sigma^2|\alpha,\beta)\\&space;&=P(\mu,\sigma^2|X_1...X_n)&space;\end{align*}" title="\begin{align*} P(X_1,...X_n,\mu,\sigma^2)&=P(X_1,..X_n|\mu,\sigma^2)P(\mu|\sigma^2)P(\sigma^2)\\ &=\prod_{i=1}^{n}[N(X_i|\mu,\sigma^2)]\times N(\mu|m,\frac{\sigma^2}{w})\times\tau^{-1}(\sigma^2|\alpha,\beta)\\ &=P(\mu,\sigma^2|X_1...X_n) \end{align*}" /></a>
