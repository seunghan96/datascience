# 2. Markov Chain Monte Carlo (MCMC)
about Markov Chains : https://d3c33hcgiwev3.cloudfront.net/_adadc80290e52a99b282ca9d7c1a41ee_background_MarkovChains.html?Expires=1583020800&Signature=UJdh6PpuE3m5EvICzH476NP5PxgoQ81DO~rCGk7a7OQcAQ-gnEjYFVSNyYoFJP2427rmBkXVLCiPdzzOWDKToMHFkzMjICyFz2QIOL0Jw0qXS-4NDXiTyeFPU~RfVeM347ZuYEkhgUqpJgMsjclK11baUhZYtMmH2g97mdMki~E_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A

## (1) Metropolis-Hastings
### a. Algorithm
Let's say our target distribution is p(theta), but we only know it up to proportionality. Let that g(theta).
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=p(\theta)&space;\propto&space;g(\theta)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(\theta)&space;\propto&space;g(\theta)" title="p(\theta) \propto g(\theta)" /></a>
</br>
</br>
These are the steps of Metropolis-Hastings Algorithms.
</br>
</br>
**Step 1)** Select initial value <a href="https://www.codecogs.com/eqnedit.php?latex=\theta_0" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta_0" title="\theta_0" /></a>
</br>
</br>
**Step 2)** for i=1....m, repeat: </br>
a) Draw candidate <a href="https://www.codecogs.com/eqnedit.php?latex=\theta^*&space;\sim&space;q(\theta^*|\theta_{i-1})" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\theta^*&space;\sim&space;q(\theta^*|\theta_{i-1})" title="\theta^* \sim q(\theta^*|\theta_{i-1})" /></a>
</br>
</br>
b) <a href="https://www.codecogs.com/eqnedit.php?latex=\alpha&space;=&space;\frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)}&space;=&space;\frac{g(\theta^*)q(\theta_{i-1}|\theta^*)}{g(\theta_{i-1})q(\theta^*|\theta_{i-1})}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\alpha&space;=&space;\frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)}&space;=&space;\frac{g(\theta^*)q(\theta_{i-1}|\theta^*)}{g(\theta_{i-1})q(\theta^*|\theta_{i-1})}" title="\alpha = \frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)} = \frac{g(\theta^*)q(\theta_{i-1}|\theta^*)}{g(\theta_{i-1})q(\theta^*|\theta_{i-1})}" /></a>
</br>
</br>
c) if alpha >= 1, accept theta* and set theta_i <- theta* </br>
   if 0<alpha<1, accept theta* and set theta_i <- theta* with probability alpha </br>
                 reject theta* and set theta_i <- theta* with probability 1-alpha
</br>

#### Interpretation
So what is the meaning of "alpha" in the algorithm above? </br>
It is the Posterior Probability of theta_new, divided by posterior probability of theta_(t-1). This can be calculated by the product of 
prior and the likelihood. Then you might understand why the algorithm is like the above.
</br>

If alpha is greater than 1 ( = the proposed move to the candidate is advantageous ) move there! </br>
If it is between 0 and 1 ( = not advantageous ) move there with probability alpha! </br>
This is also a Markov chain, because the decision to move on or not only depends on the current situation!
</br>
</br>
<img src="https://www.researchgate.net/publication/279248766/figure/fig8/AS:668369330126848@1536363074045/Illustration-of-Metropolis-Hastings-M-H-algorithm-explained-in-Figure-1.ppm" width="550" /> </br>
https://www.researchgate.net/publication/
</br>
</br>

### b. Demonstration
Let's understand the Metropolis Hastings algorithm with the example below. 
</br>

Assume there is a 60% probability that the coin is a loaded coin. The prior is that the probability of the coin is loaded. We can make use of this data when inferencing the posterior probability. Let's say that we toss this coin 5 times, and compute 
the posterior probability. In this case, there are only two outcomes for theta, which are 'fair' or 'loaded'. ( case : X=2 )
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=P(\theta&space;=&space;loaded)&space;=&space;0.6" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(\theta&space;=&space;loaded)&space;=&space;0.6" title="P(\theta = loaded) = 0.6" /></a>
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=f(\theta&space;|&space;x)&space;=&space;\frac{f(x|\theta)f(\theta)}{\sum_{\theta}^{&space;}f(x|\theta)f(\theta)}&space;=&space;\begin{pmatrix}&space;5\\&space;2&space;\end{pmatrix}[(0.5)^x(0.5)^{5-x}(0.4)I_{\theta=fair}&space;&plus;&space;(0.7)^x(0.3)^{5-x}(0.6)I_{\theta=loaded}]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(\theta&space;|&space;x)&space;=&space;\frac{f(x|\theta)f(\theta)}{\sum_{\theta}^{&space;}f(x|\theta)f(\theta)}&space;=&space;\begin{pmatrix}&space;5\\&space;2&space;\end{pmatrix}[(0.5)^x(0.5)^{5-x}(0.4)I_{\theta=fair}&space;&plus;&space;(0.7)^x(0.3)^{5-x}(0.6)I_{\theta=loaded}]" title="f(\theta | x) = \frac{f(x|\theta)f(\theta)}{\sum_{\theta}^{ }f(x|\theta)f(\theta)} = \begin{pmatrix} 5\\ 2 \end{pmatrix}[(0.5)^x(0.5)^{5-x}(0.4)I_{\theta=fair} + (0.7)^x(0.3)^{5-x}(0.6)I_{\theta=loaded}]" /></a>
</br>
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=f(\theta|X=2)&space;=&space;0.612I_{\theta=fair}&space;&plus;&space;0.388I_{\theta=loaded}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(\theta|X=2)&space;=&space;0.612I_{\theta=fair}&space;&plus;&space;0.388I_{\theta=loaded}" title="f(\theta|X=2) = 0.612I_{\theta=fair} + 0.388I_{\theta=loaded}" /></a>
</br>
</br>

Let's apply this example with the Metropolis Hastings algorithm
</br>

**[Step 1]** Start at either theta_o = fair or theta_o = loaded 
</br>

**[Step 2]** For i=1,...,m: </br>
a) Propose candidate theta* to be the other state as theta_(i-1)
</br>

b) <a href="https://www.codecogs.com/eqnedit.php?latex=\alpha&space;=&space;\frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)}&space;=&space;\frac{f(x=2|\theta^*)f(\theta^*)/1}{f(x=2|\theta_{i-1})f(\theta_{i-1})/1}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\alpha&space;=&space;\frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)}&space;=&space;\frac{f(x=2|\theta^*)f(\theta^*)/1}{f(x=2|\theta_{i-1})f(\theta_{i-1})/1}" title="\alpha = \frac{g(\theta^*)/q(\theta^*|\theta_{i-1})}{g(\theta_{i-1})/q(\theta_{i-1}|\theta^*)} = \frac{f(x=2|\theta^*)f(\theta^*)/1}{f(x=2|\theta_{i-1})f(\theta_{i-1})/1}" /></a>
</br>

if theta* is loaded, alpha = (0.0794/0.0125) = 0.635 </br>
if theta* is fair, alpha = (0.0125/0.0794) = 1.574 </br>
</br>

**[Step 3]**
If theta* is fair, then alpha >1 -> accept theta* and set theta_i = fair </br>
If theta* is loaded, then alpha < 1 -> accept theta* and set theta_i = loaded (w.p 0.635),  otherwise set theta_i=fair (w.p 0.365).</br>
</br>
Then, the transition probability matrix P would look like this.
</br>
<a href="https://www.codecogs.com/eqnedit.php?latex=P&space;=&space;\begin{bmatrix}&space;0.365&space;&0.635&space;\\&space;1&space;&&space;0&space;\end{bmatrix}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P&space;=&space;\begin{bmatrix}&space;0.365&space;&0.635&space;\\&space;1&space;&&space;0&space;\end{bmatrix}" title="P = \begin{bmatrix} 0.365 &0.635 \\ 1 & 0 \end{bmatrix}" /></a>
</br>
</br>

Let's check if we have made a good estimation ( <a href="https://www.codecogs.com/eqnedit.php?latex=\pi&space;P&space;=&space;\pi" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\pi&space;P&space;=&space;\pi" title="\pi P = \pi" /></a> ? )
</br>

We have found that the posterior probability was 
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=f(\theta|X=2)&space;=&space;0.612I_{\theta=fair}&space;&plus;&space;0.388I_{\theta=loaded}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f(\theta|X=2)&space;=&space;0.612I_{\theta=fair}&space;&plus;&space;0.388I_{\theta=loaded}" title="f(\theta|X=2) = 0.612I_{\theta=fair} + 0.388I_{\theta=loaded}" /></a>
</br>
</br>
By calculation, we can find that <a href="https://www.codecogs.com/eqnedit.php?latex=\pi&space;P&space;=&space;\pi" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\pi&space;P&space;=&space;\pi" title="\pi P = \pi" /></a> !
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=\begin{bmatrix}&space;0.612&space;&&space;0.388&space;\end{bmatrix}\begin{bmatrix}&space;0.365&space;&0.635&space;\\&space;1&space;&&space;0&space;\end{bmatrix}&space;=&space;\begin{bmatrix}&space;0.612&space;&&space;0.388&space;\end{bmatrix}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\begin{bmatrix}&space;0.612&space;&&space;0.388&space;\end{bmatrix}\begin{bmatrix}&space;0.365&space;&0.635&space;\\&space;1&space;&&space;0&space;\end{bmatrix}&space;=&space;\begin{bmatrix}&space;0.612&space;&&space;0.388&space;\end{bmatrix}" title="\begin{bmatrix} 0.612 & 0.388 \end{bmatrix}\begin{bmatrix} 0.365 &0.635 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} 0.612 & 0.388 \end{bmatrix}" /></a>
</br>
</br>

## Random walk example ( with R )
let y and mu follow the distribution below.
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=y_i&space;|&space;\mu&space;\sim&space;N(\mu,1),&space;\;\;&space;i=1,...,n" target="_blank"><img src="https://latex.codecogs.com/gif.latex?y_i&space;|&space;\mu&space;\sim&space;N(\mu,1),&space;\;\;&space;i=1,...,n" title="y_i | \mu \sim N(\mu,1), \;\; i=1,...,n" /></a>
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=\mu&space;\sim&space;t(0,1,1)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\mu&space;\sim&space;t(0,1,1)" title="\mu \sim t(0,1,1)" /></a>
</br>

Then the posterior distribution will have this form.
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=p(\mu|y_1,...,y_n)&space;\propto&space;\frac{exp[n(\bar{y}\mu&space;-&space;\mu^2/2)]}{1&plus;\mu^2}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?p(\mu|y_1,...,y_n)&space;\propto&space;\frac{exp[n(\bar{y}\mu&space;-&space;\mu^2/2)]}{1&plus;\mu^2}" title="p(\mu|y_1,...,y_n) \propto \frac{exp[n(\bar{y}\mu - \mu^2/2)]}{1+\mu^2}" /></a>
</br>

Because posterior distributions include likelihoods, which are the product of many numbers that are potentially small. To avoid problem induced by this, we're going to work on the logarithmic scale.
</br>

<a href="https://www.codecogs.com/eqnedit.php?latex=log(g(\mu))&space;=&space;n(\bar{y}\mu-\mu^2/2)-log(1&plus;\mu^2)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?log(g(\mu))&space;=&space;n(\bar{y}\mu-\mu^2/2)-log(1&plus;\mu^2)" title="log(g(\mu)) = n(\bar{y}\mu-\mu^2/2)-log(1+\mu^2)" /></a>
