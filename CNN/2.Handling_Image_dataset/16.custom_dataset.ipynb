{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 1\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, 5, 1)   # 3 channel, 20개의 filter, 5*5\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1) # 20 channel, 50개의 filter, 5*5\n",
    "        self.fc1 = nn.Linear(5*5*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 5*5*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- png형식의 data모두 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paths = glob('dataset/cifar/train/*.png')\n",
    "test_paths = glob('dataset/cifar/test/*.png')\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customize한 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(path):\n",
    "    return os.path.basename(path).split('_')[-1].replace('png','')\n",
    "\n",
    "label_names = [get_label(path) for path in train_paths]\n",
    "classes = np.unique(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot(path):\n",
    "    lbl_name = os.path.basename(path).split('_')[-1].replace('png','')\n",
    "    onehot = np.argmax(classes==lbl_name)\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_paths[idx]\n",
    "        \n",
    "        # read image\n",
    "        image = Image.open(path)#.convert(\"L\")\n",
    "        \n",
    "        # get one_hot label\n",
    "        label = get_onehot(path)\n",
    "        # label = get_label(path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(train_paths, \n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(\n",
    "                    mean=[0.406], \n",
    "                    std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(test_paths,\n",
    "           transforms.Compose([\n",
    "               transforms.ToTensor(), \n",
    "               transforms.Normalize(\n",
    "                   mean=[0.406], \n",
    "                   std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[ 0.4962,  0.6356,  0.8971,  ...,  0.4788,  0.3219,  0.0779],\n",
       "           [ 0.7402,  0.8274,  0.9319,  ...,  0.5136,  0.3393,  0.1476],\n",
       "           [ 0.8448,  0.8797,  0.8971,  ...,  0.5659,  0.4091,  0.2522],\n",
       "           ...,\n",
       "           [ 0.7751,  0.7054,  0.6705,  ...,  0.7228,  0.7925,  0.7751],\n",
       "           [ 0.5485,  0.5311,  0.5311,  ...,  0.6356,  0.6182,  0.5311],\n",
       "           [ 0.9668,  0.9145,  0.9494,  ...,  1.0888,  1.1411,  0.8971]],\n",
       " \n",
       "          [[ 0.8971,  1.0017,  1.1062,  ...,  0.8622,  0.6531,  0.4439],\n",
       "           [ 0.9668,  1.0539,  1.1237,  ...,  0.8797,  0.7054,  0.5136],\n",
       "           [ 1.0539,  1.1062,  1.1411,  ...,  0.9145,  0.7751,  0.6182],\n",
       "           ...,\n",
       "           [ 1.0365,  0.9494,  0.9145,  ...,  1.0017,  1.0191,  0.9842],\n",
       "           [ 0.8274,  0.8099,  0.8099,  ...,  0.9668,  0.9319,  0.8448],\n",
       "           [ 1.1585,  1.1062,  1.1062,  ...,  1.3154,  1.3502,  1.1237]],\n",
       " \n",
       "          [[ 0.9668,  1.0191,  1.1237,  ...,  0.4439,  0.2696,  0.1128],\n",
       "           [ 0.9319,  0.9842,  1.0714,  ...,  0.4788,  0.3219,  0.1999],\n",
       "           [ 0.9145,  0.9668,  1.0017,  ...,  0.5311,  0.3916,  0.2871],\n",
       "           ...,\n",
       "           [ 0.6879,  0.6705,  0.6531,  ...,  0.5659,  0.5136,  0.4962],\n",
       "           [ 0.4962,  0.5136,  0.5311,  ...,  0.5136,  0.4788,  0.3916],\n",
       "           [ 1.0017,  0.9494,  0.9668,  ...,  1.0539,  1.1062,  0.8622]]],\n",
       " \n",
       " \n",
       "         [[[-0.8633, -0.8110, -0.7936,  ..., -0.8807, -1.0201, -1.1421],\n",
       "           [-0.8284, -0.8110, -0.7936,  ..., -0.9853, -1.0898, -1.1770],\n",
       "           [-0.7761, -0.7936, -0.7936,  ..., -1.0550, -1.1247, -1.2119],\n",
       "           ...,\n",
       "           [-1.1421, -1.1247, -1.0724,  ..., -1.0027, -1.1073, -1.1596],\n",
       "           [-1.1247, -1.0898, -1.0376,  ..., -1.0201, -1.0550, -1.1596],\n",
       "           [-1.1596, -1.1247, -1.1073,  ..., -1.0724, -1.1247, -1.2293]],\n",
       " \n",
       "          [[-0.6715, -0.6018, -0.5844,  ..., -0.5670, -0.7238, -0.8981],\n",
       "           [-0.6715, -0.6367, -0.6193,  ..., -0.8110, -0.9156, -1.0027],\n",
       "           [-0.6193, -0.6367, -0.6367,  ..., -0.9678, -1.0201, -1.0898],\n",
       "           ...,\n",
       "           [-0.9678, -0.9504, -0.8981,  ..., -0.9156, -1.0027, -1.0376],\n",
       "           [-0.9504, -0.9156, -0.8633,  ..., -0.8981, -0.9504, -1.0550],\n",
       "           [-0.9853, -0.9504, -0.9504,  ..., -0.9678, -1.0027, -1.1247]],\n",
       " \n",
       "          [[-0.7238, -0.6890, -0.6890,  ..., -0.6193, -0.8110, -0.9853],\n",
       "           [-0.7238, -0.7064, -0.7064,  ..., -0.8981, -1.0027, -1.1073],\n",
       "           [-0.6890, -0.7413, -0.7587,  ..., -1.0898, -1.1421, -1.1944],\n",
       "           ...,\n",
       "           [-0.9504, -0.9504, -0.9156,  ..., -1.0201, -1.1073, -1.1421],\n",
       "           [-0.9156, -0.8981, -0.8807,  ..., -1.0027, -1.0376, -1.1421],\n",
       "           [-0.9504, -0.9504, -0.9330,  ..., -1.0550, -1.1073, -1.2119]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2740,  2.2740,  2.2914,  ...,  2.2043,  2.2391,  2.2740],\n",
       "           [ 2.2043,  2.2391,  1.8383,  ...,  1.7860,  2.2043,  2.1868],\n",
       "           [ 2.2043,  2.2391,  1.1062,  ...,  1.2108,  2.2043,  2.1868],\n",
       "           ...,\n",
       "           [-0.5147, -0.7936, -0.2010,  ...,  0.0605,  0.2348, -0.4798],\n",
       "           [-0.2707, -0.9156, -0.1487,  ..., -0.7936, -0.8981, -0.7413],\n",
       "           [ 1.5420,  0.8448,  1.2631,  ..., -0.9504, -1.0724, -0.6018]],\n",
       " \n",
       "          [[ 2.2914,  2.2914,  2.3263,  ...,  2.2043,  2.2391,  2.2740],\n",
       "           [ 2.2217,  2.2566,  1.8557,  ...,  1.7860,  2.2043,  2.1868],\n",
       "           [ 2.2217,  2.2391,  1.1411,  ...,  1.2108,  2.2043,  2.1868],\n",
       "           ...,\n",
       "           [-0.4973, -0.7761, -0.1835,  ...,  0.0431,  0.2348, -0.4275],\n",
       "           [-0.2532, -0.8807, -0.1312,  ..., -0.7936, -0.8284, -0.6367],\n",
       "           [ 1.5768,  0.8797,  1.2980,  ..., -0.8807, -0.9678, -0.4624]],\n",
       " \n",
       "          [[ 2.3263,  2.3263,  2.3611,  ...,  2.2043,  2.2391,  2.2740],\n",
       "           [ 2.2566,  2.2914,  1.8905,  ...,  1.7860,  2.2043,  2.2043],\n",
       "           [ 2.2566,  2.2740,  1.1585,  ...,  1.2108,  2.2043,  2.1868],\n",
       "           ...,\n",
       "           [-0.4624, -0.7238, -0.1312,  ...,  0.0779,  0.3045, -0.3230],\n",
       "           [-0.2532, -0.8807, -0.1312,  ..., -0.7587, -0.7761, -0.5495],\n",
       "           [ 1.5245,  0.8274,  1.2457,  ..., -0.8633, -0.9330, -0.3753]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.9777,  1.9777,  1.9777,  ...,  1.8383,  1.8208,  1.8383],\n",
       "           [ 2.0300,  2.0300,  2.0300,  ...,  1.9080,  1.8905,  1.8905],\n",
       "           [ 1.9951,  1.9951,  1.9951,  ...,  1.8731,  1.8557,  1.8731],\n",
       "           ...,\n",
       "           [ 1.8208,  1.7860,  1.5245,  ...,  1.6291,  1.6291,  1.6640],\n",
       "           [ 1.8383,  1.8383,  1.8557,  ...,  1.6465,  1.6465,  1.6814],\n",
       "           [ 1.7685,  1.7685,  1.7860,  ...,  1.5942,  1.5942,  1.6291]],\n",
       " \n",
       "          [[ 1.9777,  1.9777,  1.9777,  ...,  1.8383,  1.8557,  1.8731],\n",
       "           [ 2.0300,  2.0300,  2.0300,  ...,  1.9080,  1.9080,  1.9428],\n",
       "           [ 1.9951,  1.9951,  1.9951,  ...,  1.8905,  1.8731,  1.8905],\n",
       "           ...,\n",
       "           [ 1.8557,  1.7685,  1.4374,  ...,  1.6640,  1.6640,  1.6988],\n",
       "           [ 1.8383,  1.8383,  1.8557,  ...,  1.6814,  1.6814,  1.7163],\n",
       "           [ 1.7685,  1.7860,  1.7685,  ...,  1.5942,  1.6117,  1.6465]],\n",
       " \n",
       "          [[ 1.9777,  1.9777,  1.9777,  ...,  1.8383,  1.8383,  1.8557],\n",
       "           [ 2.0300,  2.0300,  2.0300,  ...,  1.9080,  1.8905,  1.9254],\n",
       "           [ 1.9951,  1.9951,  1.9951,  ...,  1.8731,  1.8557,  1.8731],\n",
       "           ...,\n",
       "           [ 1.8383,  1.7511,  1.2980,  ...,  1.6465,  1.6465,  1.6814],\n",
       "           [ 1.8383,  1.8383,  1.8034,  ...,  1.6640,  1.6640,  1.6988],\n",
       "           [ 1.7511,  1.7511,  1.7337,  ...,  1.5942,  1.5942,  1.6291]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4897,  1.2108,  0.8797,  ...,  1.4548,  1.4200,  1.4374],\n",
       "           [ 1.1411,  0.6879,  0.2522,  ...,  1.1062,  1.1411,  1.2282],\n",
       "           [ 0.9842,  0.4439, -0.0092,  ...,  0.9842,  1.1237,  1.2805],\n",
       "           ...,\n",
       "           [ 0.2522, -0.3055, -0.0441,  ..., -1.0027, -1.0724, -1.0898],\n",
       "           [ 0.4265, -0.4275, -0.0790,  ..., -0.8458, -0.9330, -0.9330],\n",
       "           [ 0.2871, -0.4798, -0.3753,  ..., -0.7238, -0.8110, -0.8110]],\n",
       " \n",
       "          [[ 2.0474,  1.8034,  1.5420,  ...,  2.0823,  2.1520,  2.1868],\n",
       "           [ 1.9951,  1.6814,  1.3154,  ...,  2.1346,  2.2566,  2.3437],\n",
       "           [ 1.7685,  1.3851,  0.9494,  ...,  1.9951,  2.1868,  2.3088],\n",
       "           ...,\n",
       "           [ 0.2696, -0.3927, -0.1661,  ..., -0.7413, -0.7587, -0.8284],\n",
       "           [ 0.4265, -0.5147, -0.2184,  ..., -0.3927, -0.4275, -0.4973],\n",
       "           [ 0.2696, -0.5844, -0.5321,  ..., -0.3404, -0.3404, -0.4101]],\n",
       " \n",
       "          [[ 2.2566,  2.1171,  1.9603,  ...,  2.4483,  2.4134,  2.5180],\n",
       "           [ 2.2043,  2.0823,  1.8208,  ...,  2.5354,  2.5354,  2.6400],\n",
       "           [ 2.0823,  1.9080,  1.5420,  ...,  2.5354,  2.5703,  2.6400],\n",
       "           ...,\n",
       "           [-0.0615, -0.5670, -0.2532,  ..., -1.0724, -1.1421, -1.1596],\n",
       "           [ 0.1476, -0.6541, -0.2532,  ..., -0.9156, -1.0201, -1.0201],\n",
       "           [ 0.1128, -0.6018, -0.4450,  ..., -0.7238, -0.8284, -0.8110]]],\n",
       " \n",
       " \n",
       "         [[[-1.1944, -1.5430, -1.6650,  ...,  0.1302,  0.1302,  0.7402],\n",
       "           [-1.5256, -1.6824, -1.6650,  ...,  0.3568,  0.1302,  0.6705],\n",
       "           [-1.6302, -1.6824, -1.6999,  ...,  0.5311,  0.1302,  0.6182],\n",
       "           ...,\n",
       "           [-1.3339, -1.6650, -1.6302,  ..., -1.7522, -1.6999, -1.0201],\n",
       "           [-1.1770, -1.7173, -1.6476,  ..., -1.7522, -1.6650, -0.9853],\n",
       "           [-0.9678, -1.6999, -1.5953,  ..., -1.7696, -1.5953, -0.8633]],\n",
       " \n",
       "          [[-1.2293, -1.5779, -1.6999,  ...,  0.1128,  0.0779,  0.6182],\n",
       "           [-1.5256, -1.6824, -1.6650,  ...,  0.3219,  0.0605,  0.5311],\n",
       "           [-1.6127, -1.6650, -1.6824,  ...,  0.4439,  0.0431,  0.4788],\n",
       "           ...,\n",
       "           [-1.4733, -1.6999, -1.6476,  ..., -1.6650, -1.6824, -1.0898],\n",
       "           [-1.3164, -1.6476, -1.6302,  ..., -1.6650, -1.6476, -1.0201],\n",
       "           [-1.1247, -1.6302, -1.5604,  ..., -1.6650, -1.5779, -0.8981]],\n",
       " \n",
       "          [[-1.2641, -1.6127, -1.7347,  ...,  0.0779,  0.0605,  0.6182],\n",
       "           [-1.5256, -1.6824, -1.6650,  ...,  0.3045,  0.0431,  0.5485],\n",
       "           [-1.5779, -1.6302, -1.6476,  ...,  0.4265,  0.0256,  0.4788],\n",
       "           ...,\n",
       "           [-1.4733, -1.7173, -1.6824,  ..., -1.6476, -1.6824, -1.1421],\n",
       "           [-1.3339, -1.7173, -1.6824,  ..., -1.6127, -1.6302, -1.0724],\n",
       "           [-1.1596, -1.6999, -1.6127,  ..., -1.6127, -1.5430, -0.9330]]]]),\n",
       " tensor([2, 3, 9, 0, 2, 9, 1, 3, 1, 8, 8, 4, 9, 1, 0, 9, 5, 1, 7, 3, 6, 2, 6, 5,\n",
       "         1, 7, 5, 2, 4, 8, 6, 2, 8, 2, 8, 7, 3, 7, 2, 5, 4, 0, 9, 9, 3, 1, 7, 4,\n",
       "         9, 2, 9, 1, 0, 4, 4, 9, 3, 9, 5, 4, 5, 2, 2, 6])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        print(data[0].shape, data[1].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
