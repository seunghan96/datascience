{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Football Dataset Classification with MLP ]\n",
    "- embedded with LINE (first-order proximity / negative sampling )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing libraries & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pd.read_csv('[Football]Embedded_with_FirstOrder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = ev.drop(ev.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865126</td>\n",
       "      <td>0.732464</td>\n",
       "      <td>0.654681</td>\n",
       "      <td>-0.280288</td>\n",
       "      <td>-0.416516</td>\n",
       "      <td>0.779290</td>\n",
       "      <td>1.989182</td>\n",
       "      <td>0.944528</td>\n",
       "      <td>0.758910</td>\n",
       "      <td>0.924716</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.315168</td>\n",
       "      <td>-1.665299</td>\n",
       "      <td>-0.984810</td>\n",
       "      <td>1.077798</td>\n",
       "      <td>0.511267</td>\n",
       "      <td>0.939566</td>\n",
       "      <td>1.635527</td>\n",
       "      <td>-0.366913</td>\n",
       "      <td>-0.451699</td>\n",
       "      <td>1.780345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.569846</td>\n",
       "      <td>-0.199044</td>\n",
       "      <td>1.784970</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>2.154936</td>\n",
       "      <td>-0.550533</td>\n",
       "      <td>-0.937430</td>\n",
       "      <td>0.107572</td>\n",
       "      <td>1.074133</td>\n",
       "      <td>0.326420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.832763</td>\n",
       "      <td>0.221549</td>\n",
       "      <td>-0.575225</td>\n",
       "      <td>-0.686977</td>\n",
       "      <td>-1.096524</td>\n",
       "      <td>0.453152</td>\n",
       "      <td>-0.012188</td>\n",
       "      <td>0.983878</td>\n",
       "      <td>0.942373</td>\n",
       "      <td>0.570720</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117742</td>\n",
       "      <td>0.502898</td>\n",
       "      <td>0.749028</td>\n",
       "      <td>0.396632</td>\n",
       "      <td>-0.188808</td>\n",
       "      <td>0.286299</td>\n",
       "      <td>1.366271</td>\n",
       "      <td>-0.073079</td>\n",
       "      <td>-0.786144</td>\n",
       "      <td>-0.255506</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.865126  0.732464  0.654681 -0.280288 -0.416516  0.779290  1.989182   \n",
       "1 -0.315168 -1.665299 -0.984810  1.077798  0.511267  0.939566  1.635527   \n",
       "2 -0.569846 -0.199044  1.784970  0.186517  2.154936 -0.550533 -0.937430   \n",
       "3  0.832763  0.221549 -0.575225 -0.686977 -1.096524  0.453152 -0.012188   \n",
       "4  0.117742  0.502898  0.749028  0.396632 -0.188808  0.286299  1.366271   \n",
       "\n",
       "          7         8         9  Label  \n",
       "0  0.944528  0.758910  0.924716      7  \n",
       "1 -0.366913 -0.451699  1.780345      0  \n",
       "2  0.107572  1.074133  0.326420      2  \n",
       "3  0.983878  0.942373  0.570720      3  \n",
       "4 -0.073079 -0.786144 -0.255506      7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42,k_neighbors=2)\n",
    "k = sm.fit_sample(ev.iloc[:,0:10],ev.iloc[:,10])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev2 = pd.DataFrame(k[0])\n",
    "ev2['Label'] = k[1]\n",
    "ev2 = ev2.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115, 11), (156, 11))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.shape, ev2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index1 = ev.groupby('Label').apply(lambda x: x.sample(frac=0.3)).index.levels[1]\n",
    "train_index1 = set(np.arange(0,ev.shape[0])) - set(test_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = ev.loc[train_index1]\n",
    "test1 = ev.loc[test_index1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = np.array(train1.iloc[:,0:10])\n",
    "train_y1 = np.array(train1.iloc[:,10]).flatten()\n",
    "test_X1 = np.array(test1.iloc[:,0:10])\n",
    "test_y1 = np.array(test1.iloc[:,10]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1_dum = pd.get_dummies(train_y1).values\n",
    "test_y1_dum = pd.get_dummies(test_y1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index2 = ev2.groupby('Label').apply(lambda x: x.sample(frac=0.3)).index.levels[1]\n",
    "train_index2 = set(np.arange(0,ev2.shape[0])) - set(test_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = ev2.loc[train_index2]\n",
    "test2 = ev2.loc[test_index2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X2 = np.array(train2.iloc[:,0:10])\n",
    "train_y2 = np.array(train2.iloc[:,10]).flatten()\n",
    "test_X2 = np.array(test2.iloc[:,0:10])\n",
    "test_y2 = np.array(test2.iloc[:,10]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y2_dum = pd.get_dummies(train_y2).values\n",
    "test_y2_dum = pd.get_dummies(test_y2).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic functions\n",
    "- 1) train_test_split\n",
    "- 2) standard scaler\n",
    "- 3) transpose & matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    return (x-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _t(X):\n",
    "    return np.transpose(X)\n",
    "\n",
    "def _m(A,B):\n",
    "    return np.matmul(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "- 1) Sigmoid\n",
    "- 2) Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.last_o = 1\n",
    "    \n",
    "    def __call__(self,X):\n",
    "        self.last_o = 1/(1+np.exp(-X))\n",
    "        return self.last_o\n",
    "    \n",
    "    def grad(self):\n",
    "        return self.last_o*(1-self.last_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.last_o = 1\n",
    "        \n",
    "    def __call__(self,X):\n",
    "        e_x = np.exp(X-np.max(X))\n",
    "        self.last_o = e_x / e_x.sum()\n",
    "        return self.last_o\n",
    "    \n",
    "    def grad(self):\n",
    "        return self.last_o*(1-self.last_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLoss:\n",
    "    def __init__(self):\n",
    "        self.dh = 1\n",
    "        self.last_diff = 1\n",
    "    \n",
    "    def __call__(self,y,yhat):\n",
    "        self.last_diff = yhat-y\n",
    "        total_loss = np.mean(y*np.log(yhat+(1e-5)) + (1-y)*np.log(1-yhat+(1e-5)))\n",
    "        return -total_loss\n",
    "    \n",
    "    def grad(self):\n",
    "        return self.last_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron :\n",
    "    def __init__(self,W,b,activation):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.act= activation()\n",
    "        \n",
    "        self.dW = np.zeros_like(self.W)  \n",
    "        self.db = np.zeros_like(self.b)\n",
    "        self.dh = np.zeros_like(_t(self.W)) \n",
    "        \n",
    "        self.last_x = np.zeros((self.W.shape[0])) \n",
    "        self.last_h = np.zeros((self.W.shape[1]))\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        self.last_x = x\n",
    "        self.last_h = _m(_t(self.W),x) + self.b\n",
    "        output = self.act(self.last_h)\n",
    "        return output\n",
    "    \n",
    "    def grad(self): \n",
    "        grad = self.act.grad()*self.W\n",
    "        return grad\n",
    "    \n",
    "    def grad_W(self,dh): \n",
    "        grad = np.ones_like(self.W) \n",
    "        grad_a = self.act.grad()   # dh/du     \n",
    "        for j in range(grad.shape[1]):\n",
    "            grad[:,j] = dh[j] * grad_a[j] * self.last_x     # previous gradient * dh/du * du/dW\n",
    "        return grad\n",
    "        \n",
    "    def grad_b(self,dh) : # dh/db = dh/du * du/db\n",
    "        grad = dh * self.act.grad() * 1  # previous gradient * dh/du * du/db\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self,input_num,output_num,hidden_depth,num_neuron, \n",
    "                 activation=Sigmoid, activation2=Softmax): \n",
    "        def init_var(in_,out_):\n",
    "            weight = np.random.uniform(-1,1,(in_,out_))\n",
    "            bias = np.zeros((out_,))\n",
    "            return weight,bias\n",
    "           \n",
    "    ## 1-1. Hidden Layer\n",
    "        self.sequence = list() # lists to put neurons\n",
    "        W,b = init_var(input_num,num_neuron)\n",
    "        self.sequence.append(Neuron(W,b,activation))\n",
    "    \n",
    "        for _ in range(hidden_depth-1):\n",
    "            W,b = init_var(num_neuron,num_neuron)\n",
    "            self.sequence.append(Neuron(W,b,activation)) # default : Sigmoid\n",
    "    \n",
    "    ## 1-2. Output Layer\n",
    "        W,b = init_var(num_neuron,output_num)\n",
    "        self.sequence.append(Neuron(W,b,activation2)) # default : Softmax\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        for layer in self.sequence:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def calc_grad(self,loss_fun):\n",
    "        loss_fun.dh = loss_fun.grad()\n",
    "        self.sequence.append(loss_fun)\n",
    "        \n",
    "        for i in range(len(self.sequence)-1, 0, -1):\n",
    "            L1 = self.sequence[i]\n",
    "            L0 = self.sequence[i-1]\n",
    "            \n",
    "            L0.dh = _m(L0.grad(), L1.dh)\n",
    "            L0.dW = L0.grad_W(L1.dh)\n",
    "            L0.db = L0.grad_b(L1.dh)\n",
    "            \n",
    "        self.sequence.remove(loss_fun)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(nn,x,y,loss_fun,lr=0.01):\n",
    "    loss = loss_fun(nn(x),y) # 1) FEED FORWARD\n",
    "    nn.calc_grad(loss_fun) # 2) BACK PROPAGATION\n",
    "    \n",
    "    for layer in nn.sequence: # Update Equation\n",
    "        layer.W += -lr*layer.dW\n",
    "        layer.b += -lr*layer.db    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y2_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3,  7,  3,  8,  8,  7,  3, 10,  2,  6,  2,  7,  9,  6,  1,  9,\n",
       "        8,  8,  7, 10,  0,  6, 11,  1,  2,  0,  6,  1,  0,  6,  2,  3,  5,\n",
       "        6,  4,  2, 11, 10, 11,  6,  1,  9,  4, 11,  2,  2,  9,  8, 10,  9,\n",
       "       11,  4,  9,  8,  8,  1,  5,  3,  6,  4, 11,  0,  5,  4,  4,  9, 10,\n",
       "        3,  6,  2,  1,  3,  7,  0,  3,  0,  4,  9, 11], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss 1.8104908214972841\n",
      "Epoch 11 : Loss 1.8113916016336296\n",
      "Epoch 21 : Loss 1.8123271189251995\n",
      "Epoch 31 : Loss 1.813300748226298\n",
      "Epoch 41 : Loss 1.8143163713077843\n",
      "Epoch 51 : Loss 1.8153784754495053\n",
      "Epoch 61 : Loss 1.8164922755066275\n",
      "Epoch 71 : Loss 1.8176638660287345\n",
      "Epoch 81 : Loss 1.8189004120990535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-9bb501a118ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_X1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y1_dum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mloss_per_epoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-28b0c32272cf>\u001b[0m in \u001b[0;36mGD\u001b[1;34m(nn, x, y, loss_fun, lr)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 1) FEED FORWARD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 2) BACK PROPAGATION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Update Equation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-464ad863f989>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-2171c008d75e>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_m\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-aef169e07543>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0me_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me_x\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0me_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_o\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \"\"\"\n\u001b[0;32m   2504\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[1;32m-> 2505\u001b[1;33m                           initial=initial)\n\u001b[0m\u001b[0;32m   2506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NeuralNet = NN(10,12,3,4,activation=Sigmoid, activation2=Softmax) # input_num, output_num, hidden_depth, num_layers\n",
    "loss_fun = LogLoss()\n",
    "EPOCH = 100\n",
    "\n",
    "loss_per_epoch = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i in range(train_X1.shape[0]):\n",
    "        loss = GD(NeuralNet,train_X1[i],train_y1_dum[i],loss_fun,0.001)\n",
    "    loss_per_epoch.append(loss)\n",
    "    \n",
    "    if epoch%10 ==0:\n",
    "        print('Epoch {} : Loss {}'.format(epoch+1, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2) train 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : Loss 1.8875529700242721\n",
      "Epoch 11 : Loss 1.8915348173126514\n",
      "Epoch 21 : Loss 1.896128997473119\n",
      "Epoch 31 : Loss 1.9010245686334544\n",
      "Epoch 41 : Loss 1.905596576751912\n",
      "Epoch 51 : Loss 1.9092643848186015\n",
      "Epoch 61 : Loss 1.9118815167054295\n",
      "Epoch 71 : Loss 1.9136491164042617\n",
      "Epoch 81 : Loss 1.9148370692308836\n",
      "Epoch 91 : Loss 1.9156525639590634\n"
     ]
    }
   ],
   "source": [
    "NeuralNet2 = NN(10,12,3,4,activation=Sigmoid, activation2=Softmax) # input_num, output_num, hidden_depth, num_layers\n",
    "loss_fun = LogLoss()\n",
    "EPOCH = 100\n",
    "\n",
    "loss_per_epoch = []\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    for i in range(train_X2.shape[0]):\n",
    "        loss = GD(NeuralNet,train_X2[i],train_y2_dum[i],loss_fun,0.001)\n",
    "    loss_per_epoch.append(loss)\n",
    "    \n",
    "    if epoch%10 ==0:\n",
    "        print('Epoch {} : Loss {}'.format(epoch+1, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,test_X):\n",
    "    preds = []\n",
    "    for i in range(test_X.shape[0]):\n",
    "        pred_result = np.argmax(model(test_X[i]))\n",
    "        preds.append(pred_result)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuralNet2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-4c3ee9cec555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNet2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_X2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'NeuralNet2' is not defined"
     ]
    }
   ],
   "source": [
    "predict(NeuralNet2,test_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics(pred,actual):\n",
    "    TP,TN,FP,FN = 0,0,0,0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]*actual[i]==1:\n",
    "            TP +=1\n",
    "        elif pred[i]>actual[i]:\n",
    "            FP +=1\n",
    "        elif pred[i]<actual[i]:\n",
    "            FN +=1\n",
    "        else:\n",
    "            TN +=1\n",
    "    \n",
    "    accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
    "    precision = TP / (TP+FP)\n",
    "    recall = TP / (TP+FN)\n",
    "    F1_score = 2*(precision*recall)/(precision+recall)\n",
    "    return accuracy,precision,recall,F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Dataset 70%')\n",
    "actual_class_70 = (1-test_y_70)[:,0]\n",
    "Metrics(pred70,actual_class_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
