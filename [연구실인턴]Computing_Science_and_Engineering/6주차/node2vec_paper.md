# node2vec : Scalable Feature Learning for Networks

## 1. Introduction
- semi-supervised algorithm for scalable feature learning in networks
- "learning continuous feature representations for nodes in network" ( into low dimension ) </br>
( classical approach : PCA, Multi-Dimensional Scaling )
- use **2nd order random walk** approach to generate network neighborhoods
( contribution : defning a flexible notion of a node's network neighborhood )
- use feature representations not only of nodes, but also **"edges"**

### [ KEY CONTRIBUTION ]
1. efficient scalable algorithm for feature learning in networks (using SGD)
2. provides flexibilty in discovering representations 
3. extend node2vec from 'nodes' -> 'edges'
4. evaluate node2vec for (1) multi-label classification & (2) link prediction
 * (1) multi-label classification : which class does each node belongs to
 * (2) link prediction : predict whether there is a connection between two nodes
</br>
</br>

## 2. Feature learning Framework
- applicable to any (un)directed & (un)weighted network
- extend Skip-Gram architecture to networks </br>
** skip-gram : https://github.com/seunghan96/datascience/blob/master/%5B%EC%97%B0%EA%B5%AC%EC%8B%A4%EC%9D%B8%ED%84%B4%5DComputing_Science_and_Engineering/1%EC%A3%BC%EC%B0%A8/DeepWalk_Online_Learning_of_Social_Representations.md 
- propose a randomized procedure that samples many different neighbors of a source node!
- network : <a href="https://www.codecogs.com/eqnedit.php?latex=G&space;=&space;(V,E)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?G&space;=&space;(V,E)" title="G = (V,E)" /></a> </br>
mapping function (from nodes -> feature representations) : <a href="https://www.codecogs.com/eqnedit.php?latex=f&space;:&space;V&space;\rightarrow&space;\mathbb{R}^d" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f&space;:&space;V&space;\rightarrow&space;\mathbb{R}^d" title="f : V \rightarrow \mathbb{R}^d" /></a> </br>
  ( d : number of dimension of feature representation ) </br>
  ( <a href="https://www.codecogs.com/eqnedit.php?latex=f" target="_blank"><img src="https://latex.codecogs.com/gif.latex?f" title="f" /></a> : matrix size of <a href="https://www.codecogs.com/eqnedit.php?latex=|V|\times&space;d" target="_blank"><img src="https://latex.codecogs.com/gif.latex?|V|\times&space;d" title="|V|\times d" /></a> ) </br>
network neighborhood of node u ( generated by neighborhood sampling strategy S ): <a href="https://www.codecogs.com/eqnedit.php?latex=N_s(u)&space;\subset&space;V" target="_blank"><img src="https://latex.codecogs.com/gif.latex?N_s(u)&space;\subset&space;V" title="N_s(u) \subset V" /></a> </br>

### [ Objective Function ]
- maximize log-probability of observing a network neighborhood (<a href="https://www.codecogs.com/eqnedit.php?latex=N_s(u)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?N_s(u)" title="N_s(u)" /></a>) for a node u, conditioned on its feature representation( = f(u) ) </br> </br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\underset{f}{max}&space;\sum_{u&space;\in&space;V}^{&space;}logPr(N_s(u)|f(u))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\underset{f}{max}&space;\sum_{u&space;\in&space;V}^{&space;}logPr(N_s(u)|f(u))" title="\underset{f}{max} \sum_{u \in V}^{ }logPr(N_s(u)|f(u))" /></a>

### [ Two Assumptions ]
**1) Conditional Independence**
- factorize the likelihood, by assuming independence among likelihood of obesrving a neighborhood nodes </br> </br>
  <a href="https://www.codecogs.com/eqnedit.php?latex=Pr(N_s(u)|f(u))&space;=&space;\prod_{n_i&space;\in&space;N_s(u)}^{&space;}&space;Pr(n_i|f(u))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Pr(N_s(u)|f(u))&space;=&space;\prod_{n_i&space;\in&space;N_s(u)}^{&space;}&space;Pr(n_i|f(u))" title="Pr(N_s(u)|f(u)) = \prod_{n_i \in N_s(u)}^{ } Pr(n_i|f(u))" /></a>
</br>

**2) Symmetry in feature space**
- source node & neighborhood node -> have symmetric effect over each other in feature space
- conditional likelihood of source-neighborhood node pair ( as a softmax ) : </br> </br>
<a href="https://www.codecogs.com/eqnedit.php?latex=Pr(n_i|f(u))&space;=&space;\frac{exp(f(n_i)&space;\cdot&space;f(u))}{\sum_{v&space;\in&space;V}^{&space;}exp(f(n_i)&space;\cdot&space;f(u))}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Pr(n_i|f(u))&space;=&space;\frac{exp(f(n_i)&space;\cdot&space;f(u))}{\sum_{v&space;\in&space;V}^{&space;}exp(f(n_i)&space;\cdot&space;f(u))}" title="Pr(n_i|f(u)) = \frac{exp(f(n_i) \cdot f(u))}{\sum_{v \in V}^{ }exp(f(n_i) \cdot f(u))}" /></a> 
</br>

with these two assumption, the objective function can be simplified into </br> </br>
<a href="https://www.codecogs.com/eqnedit.php?latex=\underset{f}{max}&space;\sum_{u&space;\in&space;V}^{&space;}&space;[&space;-logZ_u&plus;&space;\sum_{n_i&space;\in&space;N_S(u)}f(n_i)&space;\cdot&space;f(u)]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\underset{f}{max}&space;\sum_{u&space;\in&space;V}^{&space;}&space;[&space;-logZ_u&plus;&space;\sum_{n_i&space;\in&space;N_S(u)}f(n_i)&space;\cdot&space;f(u)]" title="\underset{f}{max} \sum_{u \in V}^{ } [ -logZ_u+ \sum_{n_i \in N_S(u)}f(n_i) \cdot f(u)]" /></a> </br> </br>
( in the above, <a href="https://www.codecogs.com/eqnedit.php?latex=Z_u&space;=&space;\sum_{v&space;\in&space;V}^{&space;}exp(f(u)\cdot&space;f(v))" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Z_u&space;=&space;\sum_{v&space;\in&space;V}^{&space;}exp(f(u)\cdot&space;f(v))" title="Z_u = \sum_{v \in V}^{ }exp(f(u)\cdot f(v))" /></a> is too expensive to compute! use negative sampling ) </br> </br>
** negative sampling : https://github.com/seunghan96/datascience/blob/master/%5B%EC%97%B0%EA%B5%AC%EC%8B%A4%EC%9D%B8%ED%84%B4%5DComputing_Science_and_Engineering/4%EC%A3%BC%EC%B0%A8/Negative_Sampling.md </br>

</br>

## 3-1. Class search strategies
- sample neighbors of a source node as a form of local search

### [ two kind of similarities ]
 1) **homophily**
 - highly interconnected -> should be embedded closely </br>
 - macro view
 - infer communities based on distances </br>
  ( ex. u & s1 : community A, s8 & s9 : community B ) </br>
 2) **structural equivalence**
 - similar structural roles -> embedded together </br>
 - micro view( example with the image above : u & s6 )
 - does not emphasize connectivity! </br>
  ( ex. u & s6 : act as hubs of communities ) 
</br>

### [ two search algorithms ]
- two sampling strategies for generating neighborhood sets N(s) of k nodes ( BFS & DFS )
<img src="https://i.stack.imgur.com/vm0sn.png" width="450" /> </br>
(https://i.stack.imgur.com/vm0sn.png)

#### a. Breadth-first Sampling(BFS)
- neighborhood : only immediate neighbors of the source node
- micro-view
- for 'structural equivalence' </br> 

#### b. Depth-first Sampling(DFS) </br>
- neighborhood : nodes sequentially sampled at increasing distance from the source node
- macro-view
- for 'homophily' </br>
</br>
** BFS & DFS implementation : (https://github.com/seunghan96/datascience/tree/master/Data_Structure/2.Algorithm/Graph_Algorithm)
