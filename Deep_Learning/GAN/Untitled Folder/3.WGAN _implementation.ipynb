{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. WGAN 구현하기\n",
    "- DCGAN과의 차이점 : Loss Function을 **베서슈타인 손실 함수**로 사용한다는 점\n",
    "- 그 외의 원리는 전부 동일하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Generator\n",
    "- input : noise vector와, 만들어 낼 image의 크기\n",
    "- output : (fake) image를 만드는 generator\n",
    "\n",
    "layer의 구성 :\n",
    "- 1) Batch Normalization\n",
    "- 2) Activation Function ( ReLU & Sigmoid )\n",
    "- 3) Conv2DTranspose ( Deconvolution을 해주는 layer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(inputs, img_size):\n",
    "    # (1) image크기 조정\n",
    "    img_resize = img_size//4\n",
    "    \n",
    "    # (2) parameter\n",
    "    kernel_s = 5\n",
    "    filters = [64,64,32,1]\n",
    "    \n",
    "    # (3) input\n",
    "    x = Dense(img_resize * img_resize * filters[0])(inputs)\n",
    "    x = Reshape((img_resize,img_resize,filters[0]))(x)\n",
    "    \n",
    "    for f in filters:\n",
    "        if f > filters[-2]: # first 2 layers : stride=2, last 2 layers : stride=1\n",
    "            stride = 2\n",
    "        else :\n",
    "            stride =1\n",
    "        x = BatchNormalization()(x) # (1) BN\n",
    "        x = Activation('relu')(x) # (2) ReLU\n",
    "        x = Conv2DTranspose(filters=f,kernel_size=kernel_s,strides=stride,padding='same')(x) # (3) Deconvolution\n",
    "    \n",
    "    x = Acivation('Sigmoid')(x) # (4) Sigmoid\n",
    "    G = Model(inputs,x,name='generator')\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Discriminator\n",
    "- input : image\n",
    "- output : 0~1 사이의 값 (0:fake ~ 1:real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(inputs):\n",
    "    \n",
    "    # (1) parameter\n",
    "    kernel_s = 5\n",
    "    filters = [32,64,128,256]\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    for f in filters:\n",
    "        if f == filters[-1]: # first 3 filters : stride=2, last layer : stride=1\n",
    "            stride = 1\n",
    "        else :\n",
    "            stride = 2\n",
    "        x = ReLU(x) # (1) ReLU\n",
    "        x = Conv2D(filters=f, kernel_size=kernel_s, strides=stride,padding='same')(x) # (2) Convolutional Layer\n",
    "    \n",
    "    x = Flatten()(x) # (3) Flatten\n",
    "    x = Dense(1)(x) # (4) Dense\n",
    "    x = Activation('sigmoid')(x) # (5) Sogmoid\n",
    "    D = Model(inputs,x,name='discriminator')\n",
    "    \n",
    "    return D    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Implement GAN with Generator & Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_GAN():\n",
    "    (x_train,_),(_,_) = mnist.load_data() # only need image ( no label )\n",
    "    \n",
    "    # 1. Reshape Image\n",
    "    img_size = x_train.shape[1] # (= 28)\n",
    "    x_train = np.reshape(x_train, [-1,img_size,img_size,1]) # into 28,28,1\n",
    "    x_train = x_train.astype('float32')/255\n",
    "    \n",
    "    # 2. parameter\n",
    "    model_name = 'WGAN'\n",
    "    dim = 100 \n",
    "    n_critic = 5 # Discriminator가 5회 훈련되는 동안, Generator는 1회 훈련\n",
    "    clip_val = 0.01 # Discriminator의 weight를 제한\n",
    "    batch_size = 64 \n",
    "    train_steps = 10000\n",
    "    lr = 2e-4    \n",
    "    input_shape = (img_size,img_size,1)\n",
    "    \n",
    "    # 3-1. Discriminator\n",
    "    inputs = Input(shape=input_shape, name='D_input')\n",
    "    D = Discriminator(inputs, activation='linear')\n",
    "    D.compile(loss=wasserstein_loss, optimizer=RMSprop(lr=lr),metrics=['accuracy']) # 베서슈타인 손실 함수 사용!\n",
    "    D.summary()\n",
    "    \n",
    "    # 3-2. Generator\n",
    "    inputs2 = Input(shape=(dim,), name='G_input')\n",
    "    G = Generator(inputs2, img_size)\n",
    "    G.summary()\n",
    "    \n",
    "    # 4. Adversarial Update\n",
    "    D.trainable = False    \n",
    "    GAN = Model(inputs2, D(G(inputs2)),name=model_name)\n",
    "    GAN.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=lr))\n",
    "    GAN.summary()\n",
    "    \n",
    "    # 5. Training\n",
    "    models = (G,D,GAN)\n",
    "    params = (dim,batch_size,n_critic,clip_val,train_steps,model_name)\n",
    "    train(models,x_train,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGAN_train(models,x_train,params):\n",
    "    \n",
    "    G,D,GAN = models\n",
    "    (dim,batch_size,n_critic,clip_val,train_steps,model_name) = params\n",
    "    save_point = 500\n",
    "    \n",
    "    # sample data ( 확인용 )\n",
    "    noise_vec = np.random.uniform(-1,1,size=[16,dim])\n",
    "    train_size = x_train.shape[0]\n",
    "    label_real = np.nes((batch_size,1))\n",
    "    \n",
    "    ####################[  Discriminator  ]###################\n",
    "    \n",
    "    # 1번의 train_step\n",
    "    for i in range(train_steps):\n",
    "        \n",
    "        # n_critic번의 Discriminator 훈련        \n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        \n",
    "        for _ in range(n_critic):\n",
    "            \n",
    "            # 1) real image\n",
    "            randoms = np.random.randint(0,train_size,size=batch_size) # select random images\n",
    "            image_real = x_train[randoms]\n",
    "            \n",
    "            # 2) fake image\n",
    "            noise = np.random.uniform(-1,1,size=[batch_size,latent_size]) \n",
    "            image_fake = G.predict(noise)\n",
    "        \n",
    "            # 기존의 방법 : real & fake image를 결합했었음\n",
    "            # 새로운 방법 : real로 이루어진 batch & fake로 이루어진 batch -> 교대로 훈련\n",
    "            # x = np.concatenate((image_real,image_fake))\n",
    "            # y = np.ones([2*batch_size,1])\n",
    "            # y[batch_size:,:] = 0\n",
    "            \n",
    "            # 3) train\n",
    "            real_loss, real_acc = D.train_on_batch(image_real,label_real) # 진짜 image 학습\n",
    "            fake_loss, fake_acc = D.train_on_batch(image_fake,label_real) # 가짜 image 학습\n",
    "            \n",
    "            loss += 0.5*(real_loss + fake_loss)\n",
    "            acc += 0.5*(real_acc + fake_acc)\n",
    "            \n",
    "            for layer in D.layers:\n",
    "                W = layer.get_weights()\n",
    "                W = [np.clip(w, -clip_val, clip_val) for w in W]\n",
    "                layer.set_weights(W)\n",
    "            \n",
    "            loss /= n_critic\n",
    "            acc /= n_critic\n",
    "            temp = \"%d : [Discriminator loss : %f, accuracy : $f]\" % (i,loss,acc)\n",
    "       \n",
    "    \n",
    "    ####################[  Generator  ]###################\n",
    "    \n",
    "    # 1) train\n",
    "    loss, acc = GAN.train_on_batch(noise_vec,label_real)\n",
    "    temp = \"%d : [Generator loss : %4, accuracy : $f]\" % (i,loss,acc)\n",
    "    print(temp)\n",
    "    \n",
    "    # 2) show results\n",
    "    if (i+1) % save_point ==0:\n",
    "        if (i+1) == train_steps:\n",
    "            show = True\n",
    "        else :\n",
    "            show = False            \n",
    "            plot_images(G,noise_input = noise_vec,show=show,\n",
    "                       step=(i+1),model_name=model_name)\n",
    "            \n",
    "    G.save(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
