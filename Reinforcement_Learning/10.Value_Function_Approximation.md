# 10. Value Function Approximation
## 1. Introduction
Planning(Dynamic) & Learning(MC, TD)을 통해 문제 해결 </br>
지금까지는 tabular method를 활용하여 value-function을 구해왔음. </br>
( tabular method : grid 형식처럼, 각각의 state가 하나의 grid가 되고, action은 상/하/좌/우 중 하나로 움직여서 인접한 grid로 state가 넘어가는 단순한 형태 )</br></br>
<img src="https://cs.stanford.edu/people/karpathy/img/mdpdp.jpeg" width="200" /> </br>
( **tabular method 형태** 출처 : https://cs.stanford.edu/people/karpathy/img/mdpdp.jpeg )

하지만 state & action의 경우가 훨씬 많아지고 복잡해지면, 이를 적용하기 쉽지 않다. 
또한, 이를 일반화(generalization)할 수 있는 식을 찾기 위해 등장한 것이 **value-function approximation**이다.

## 2. Function Approximation
Function Approximation으로 value-function을 구한다!
### (1) 장점
- 실제 존재하지 않는 data도 function을 통해 계산 가능
- 실제 data의 noise를 배제하고 학습 가능
- 고차원의 data도 효율적으로 저장 가능

### (2) finding parameters
간단한 표현으로, y=ax+b의 parameter a,b의 적절한 값을 찾아주는 것이다. 많은 모델들이 있는데, 최근 들어 좋은 성능을 내는 Neural Net이 대표적인
방법이다. (간략한 소개 : layer&node로 구성되어 있는 model / back propagation을 사용하여 weight & bias를 update하여 최적의 값을 찾음. 자세한 것은 https://github.com/seunghan96/datascience/tree/master/Deep_Learning/Basic_of_NN 참고 ) </br> </br>

### (3) Gradient Descent
#### a. value-function
Gradient Descent(경사하강법)을 이용하여 적절한 parameter값을 찾아나간다. 이를 RL의 value-function에 적용하자면, update하는 대상은 true-value function이 되고, minimize해야 하는 objective function은 다음 식과 같이 true-value function과 approximated-value function의 MSE로 잡을 수 있다. </br></br>
<img src="https://t1.daumcdn.net/cfile/tistory/99947D3F5A6EB5FD35" width="270" /> </br>  </br>
위 식을 G.D를 이용하여 풀면 다음과 같은 식을 얻을 수 있다. (update할 target은 MC,TD에 따라 다름) 
<img src="https://t1.daumcdn.net/cfile/tistory/99CEC4385A6EB9F81D" width="350" /> </br> </br>
<img src="https://t1.daumcdn.net/cfile/tistory/99A4993A5A6EB6A207" width="460" /> </br>
<img src="https://t1.daumcdn.net/cfile/tistory/996FBD3F5A6FCE5E1F" width="570" /> </br>
</br></br>
#### b. action-value function
model-free를 위해, (state)value function대신 action-value function을 사용해서도 이 문제를 풀 수 있다. 위의 a.value-function에서 action이 추가된 것 이외에 다른 부분은 전부 동일하다. </br></br>
<img src="https://t1.daumcdn.net/cfile/tistory/99EF1B395A6FCDD320" width="370" /> 
</br>
<img src="https://t1.daumcdn.net/cfile/tistory/9996EA3D5A6FCDAF28" width="750" /> </br></br>
이 역시도 update할 target에 변형을 줄 수 있다. (자세한 내용은 이전 포스트들 참고) </br>
<img src="https://t1.daumcdn.net/cfile/tistory/99FDD74E5A6FCF7B26" width="550" />
<img src="https://t1.daumcdn.net/cfile/tistory/991DAA4D5A6FCF9115" width="750" />
<img src="https://t1.daumcdn.net/cfile/tistory/99B0AA4C5A6FD00827" width="750" />
<img src="https://t1.daumcdn.net/cfile/tistory/9922E9425A6FD1D32E" width="750" />
( 출처 : https://t1.daumcdn.net/cfile/tistory/9922E9425A6FD1D32E )

#### Gradient Descent ( Batch Gradient Descent, Stochastic Gradient Descent에 대해서는 Deep Learning part에서 많이 다뤘으므로 생략한다 )
