# 3. Dynamic Programming
## 1) Dynamic Programming & MDP
Dynamic Programming(동적 계획법)은, 쉽게 말해서 풀고하자 하는 문제를 작은 여러 개의 하위 문제로 나눠서 푸는 것을 의미한다.  </br >
( https://github.com/seunghan96/datascience/tree/master/Data_Structure/2.Algorithm 참고 ) </br>
Dynamic Programming을 하기 위한 조건에는 다음과 같이 두 가지가 있다
- 1 ) 하나의 문제를 "여러 개의 작은 문제"로 나눌 수 있어야 한다.
- 2 ) 하나의 서브 문제를 풀고 난 뒤, 여기서 나온 솔루션을 "저장"할 수 있어야 한다.

는 그리고 앞에서 배운 MDP(Markov Decision Process)는 이 두 조건을 만족한다. MDP의 value function을 들여다 보면, v(s)를 구하기 위해 그 안에 있는 v(s+1)을 구하는 recursive 형태를 보이는 것을 알 수 있다. </br> </br>
<a href="https://www.codecogs.com/eqnedit.php?latex=v(s)&space;=&space;E[R_{t&plus;1}&plus;\gamma&space;v(S_{t&plus;1})|S_t=s]" target="_blank"><img src="https://latex.codecogs.com/gif.latex?v(s)&space;=&space;E[R_{t&plus;1}&plus;\gamma&space;v(S_{t&plus;1})|S_t=s]" title="v(s) = E[R_{t+1}+\gamma v(S_{t+1})|S_t=s]" /></a> </br> </br>
이렇게 Dynamic Programming을 이용하여 MDP문제를 풀 수 있는데, 여기에는 크게 2가지 방법이 있다. ( 1. Policy Iteration & 2. Value Iteration )

### 2) Policy Iteration
Policy Iteration은 다음과 같은 방식으로 진행이 이루어진다. <br>
1) Initialize <a href="https://www.codecogs.com/eqnedit.php?latex=\pi" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\pi" title="\pi" /></a> randomly 
2) Repeat until converge
 - let <a href="https://www.codecogs.com/eqnedit.php?latex=V&space;=&space;V_\pi" target="_blank"><img src="https://latex.codecogs.com/gif.latex?V&space;=&space;V_\pi" title="V = V_\pi" /></a>
 - for each state s, let <a href="https://www.codecogs.com/eqnedit.php?latex=\pi(s)&space;=&space;\underset{a\in&space;A}{argmax}&space;\gamma&space;\sum_{s'\in&space;S}^{&space;}P_{sa}(s')V^*(s')" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\pi(s)&space;=&space;\underset{a\in&space;A}{argmax}&space;\gamma&space;\sum_{s'\in&space;S}^{&space;}P_{sa}(s')V^*(s')" title="\pi(s) = \underset{a\in A}{argmax} \gamma \sum_{s'\in S}^{ }P_{sa}(s')V^*(s')" /></a> </br>
 즉, 처음에 policy를 랜덤하게 초기값을 주고, return을 최대로 만드는 action을 선택하는 방향으로 계속 policy를 update해나가는 과정이다.
 여기서 Policy Iteration은 2가지로 진행이 된다 ( Policy Evaluation & Policy Improvement )
 
 #### a. Policy Evaluation
 policy evaluation, 말 그대로 '정책 평가'이다. 한 마디로, 현재 가지고 있는 policy에 따라 행동을 했을 경우, 각각의 state에서 agent가 얻게 되는 예상 return값들을 value로 계산하는 과정이다. 다음의 예시를 통해 이해해보자.
 [ Example ] 
 ( 출처 : https://t1.daumcdn.net/cfile/tistory/99E206335A4770B42E )
 <img src = 'https://t1.daumcdn.net/cfile/tistory/99E206335A4770B42E', height=650>
 

