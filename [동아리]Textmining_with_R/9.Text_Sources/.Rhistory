# (1) 필요한 rvest 라이브러리 불러오기
library(rvest)
# (2) 크롤링할 url 읽어오기 (single page)
url<-'http://www.amazon.com/gp/help/customer/forums/ ref=cs_hc_g_tv?i.e.=UTF8&forumID=Fx1SKFFP8U1B6N5&cdThr ead=Tx3JJLVOS6N6YSD'
page<-read_html(url)
page<-read_html(url)
# (2) 스크래핑할 url 읽어오기 (single page)
url<-'http://www.amazon.com/gp/help/customer/forums/ref=cs_hc_g_tv?i.e.=UTF8&forumID=Fx1SKFFP8U1B6N5&cdThread=Tx3JJLVOS6N6YSD'
page<-read_html(url)
# (2) 스크래핑할 url 읽어오기 (single page)
url<-'https://www.amazon.com/s?k=korea'
page<-read_html(url)
# Chrome extension called “SelectorGadget.” It is available at www.selectorgadget.com
# Chrome 우측 상단에 새로운 팝업 생김 -> 돋보기 click
# (3)
posts<-html_nodes(page, '.thread-body')
forum.posts<-html_text(posts)
# (4)
# 스크래핑 된 문서의 어디든 : "//"
# 모든(all)" 링크를 가져오기 때문에 : "a"
links<-html_nodes(page,xpath='//a')
# Permalink 골라내기 ( 고유한 link )
thread.urls<-grep("*Permalink*", links)
# href 특성 가진 것들
thread.urls<-html_attr(links,"href")[thread.urls]
# www.amazon.com뒤에 붙여넣어
thread.urls<-paste0('www.amazon.com',thread.urls)
thread.urls
library(GuardianR)
library(qdap)
# 자신의 key 입력
# 해당 날짜 범위 안에 있는 'brexit'라는 단어를 찾아냄
key<-'0c1d6c32-c3a7-4d83-9c66-775ba5f8926a'
text <- get_guardian("Brexit", from.date="2016-0701",to.date="2016-07-06",api.key=key)
text <- get_guardian("Brexit", from.date="2016-07-01",to.date="2016-07-06",api.key=key)
# iconv로 string conversion (latin1 -> ASCII)
body<-iconv(text$body, "latin1", "ASCII", sub="")
