# Text to Vectors using text2vec
library(data.table)
library(text2vec)
library(tm)
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\Airbnb-boston_only\\Airbnb-boston_only.csv')
airbnb <- data.table(review_id = text$review_id,
comments = text$comments,
review_scores_rating = text$review_scores_rating)
airbnb$comments <- removeWords(airbnb$comments, c(stopwords('en'),'Boston'))
airbnb$comments <- removePunctuation(airbnb$comments)
airbnb$comments <- stripWhitespace(airbnb$comments)
airbnb$comments <- removeNumbers(airbnb$comments)
airbnb$comments <- tolower(airbnb$comments)
tokens <- strsplit(airbnb$comments, split= " ", fixed=T)
vocab <- create_vocabulary(itoken(tokens), ngram=c(1,1))
vocab <- prune_vocabulary(vocab, term_count_min=5)
vocab[[1]][221:225]
iter <- itoken(tokens)
vectorizer <- vocab_vectorizer(vocab, grow_dtm=F, skip_grams_window=5)
# Text to Vectors using text2vec
library(data.table)
library(text2vec)
library(tm)
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\Airbnb-boston_only\\Airbnb-boston_only.csv', encoding='UTF-8')
airbnb <- data.table(review_id = text$review_id,
comments = text$comments,
review_scores_rating = text$review_scores_rating)
airbnb$comments <- removeWords(airbnb$comments, c(stopwords('en'),'Boston'))
airbnb$comments <- removePunctuation(airbnb$comments)
airbnb$comments <- stripWhitespace(airbnb$comments)
airbnb$comments <- removeNumbers(airbnb$comments)
airbnb$comments <- tolower(airbnb$comments)
tokens <- strsplit(airbnb$comments, split= " ", fixed=T)
vocab <- create_vocabulary(itoken(tokens), ngram=c(1,1))
vocab <- prune_vocabulary(vocab, term_count_min=5)
vocab[[1]][221:225]
iter <- itoken(tokens)
vectorizer <- vocab_vectorizer(vocab, grow_dtm=F, skip_grams_window=5)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(iter, vectorizer,skip_grams_window=5)
str(tcm)
fit.glove <- glove(tcm=tcm, word_vectors_size = 50, x_max=10, learning_rate = 0.2, num_iters=15)
fit.glove<- GlobalVectors$new(word_vectors_size = 50, vocabulary =vocab , x_max=10, learning_rate=0.2)
word.vectors<-fit.glove$fit_transform(x=tcm, n_iter=15)
rownames(word.vectors) <- rownames(tcm)
word.vec.norm <- sqrt(rowSums(word.vectors^2))
good.walks <- word.vectors['walk', , drop=FALSE] - word.vectors['disappointed', , drop=FALSE] + word.vectors['good', , drop=FALSE]
cos.dist <- text2vec:::cosine(good.walks,
word.vectors,
word.vec.norm)
cos.dist<-sim2(x = word.vectors, y=good.walks, method = "cosine", norm = "l2")
head(sort(cos.dist[,1], decreasing = T), 10)
cos.dist<- sim2(x = word.vectors, y=dirty.sink, method = "cosine", norm = "l2")
dirty.sink <- word.vectors['sink', , drop=FALSE] - word.vectors['condition', , drop=FALSE] + word.vectors['dirty', , drop=FALSE]
cos.dist<- sim2(x = word.vectors, y=dirty.sink, method = "cosine", norm = "l2")
head(sort(cos.dist[,1], decreasing = T), 10)
# Text to Vectors using text2vec
library(data.table)
library(text2vec)
library(tm)
# 1
library(data.table)
library(text2vec)
library(tm)
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\Airbnb-boston_only\\wine.csv', encoding='UTF-8')
# 2
wine<- data.table(comments=text$description)
wine<-wine[1:50000]
# 1
library(data.table)
library(text2vec)
library(tm)
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\Airbnb-boston_only\\wine.csv', encoding='UTF-8')
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\wine.csv', encoding='UTF-8')
# 2
wine<- data.table(comments=text$description)
wine<-wine[1:50000]
# 3
wine$comments <- removePunctuation(wine$comments)
wine$comments <- stripWhitespace(wine$comments)
wine$comments <- removeNumbers(wine$comments)
wine$comments <- tolower(wine$comments)
# 4
tokens <- strsplit(wine$comments, split= " ", fixed=T)
# 5
vocab <- create_vocabulary(itoken(tokens), ngram=c(1,1))
# 6
vocab <- prune_vocabulary(vocab, term_count_min=5)
# 7
iter <- itoken(tokens)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(iter, vectorizer,skip_grams_window=5)
# 8
fit.glove<- GlobalVectors$new(word_vectors_size = 50, vocabulary =vocab , x_max=10, learning_rate=0.2)
# 9
word.vectors<-fit.glove$fit_transform(x=tcm, n_iter=15)
head(vocab$term,descending=T,6)
head(vocab$term,descending=T,40)
# 10
head(vocab$term,descending=T,40)
# 10
vocab(term(head(order(vocab$term_count,decreasing=T),40)))
# 10
library(vocab)
# 10
library(text2vec)
vocab(term(head(order(vocab$term_count,decreasing=T),40)))
head(vocab$term,descending=T,40)
head(vocab$term[order(vocab$term_count,decreasing=T)],40)
text <- fread('C:\\Users\\samsung\\Desktop\\Bitamin\\Textmining with R\\5장\\wine.csv', encoding='UTF-8')
# 2
wine<- data.table(comments=text$description)
wine<-wine[1:50000]
# 3
wine$comments <- removePunctuation(wine$comments)
wine$comments <- stripWhitespace(wine$comments)
wine$comments <- removeNumbers(wine$comments)
wine$comments <- tolower(wine$comments)
# 4
tokens <- strsplit(wine$comments, split= " ", fixed=T)
# 5
vocab <- create_vocabulary(itoken(tokens), ngram=c(1,1))
# 6
vocab <- prune_vocabulary(vocab, term_count_min=5)
# 7
iter <- itoken(tokens)
vectorizer <- vocab_vectorizer(vocab)
tcm <- create_tcm(iter, vectorizer,skip_grams_window=5)
# 8
fit.glove<- GlobalVectors$new(word_vectors_size = 40, vocabulary =vocab , x_max=10, learning_rate=0.2)
# 9
word.vectors<-fit.glove$fit_transform(x=tcm, n_iter=15)
# 10
library(text2vec)
head(vocab$term[order(vocab$term_count,decreasing=T)],40)
# 3
wine$comments <- removeWords(wine$comments, c(stopwords('en')))
